<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>时事 on 谷粒的博客</title>
    <link>https://kuhungio.me/tags/%E6%97%B6%E4%BA%8B/</link>
    <description>Recent content in 时事 on 谷粒的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 14 Apr 2019 11:51:09 +0800</lastBuildDate><atom:link href="https://kuhungio.me/tags/%E6%97%B6%E4%BA%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>如何设计一套类似视觉中国“鹰眼”的技术</title>
      <link>https://kuhungio.me/2019/vgc-it/</link>
      <pubDate>Sun, 14 Apr 2019 11:51:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/vgc-it/</guid>
      <description>这两天除了马总的 996， 互联网上最火的莫属被黑洞绊倒的视觉中国了。视觉中国因黑洞图的版权争端，被卷入更大的争端。一时间舆论哗然，其股票连续跌停。他是如何一步步壮大，又是为何跌倒的呢？往前看几年，起底其历史：公开资料显示，“视觉中国凭借其‘鹰眼技术’，有力的打击了“盗版”并成功形成了自己的商业模式。”
 2016年初公司开发图像追踪系统，通过人工智能、图像比对、爬虫技术，能够追踪公司拥有代理权的图片在网络上的使用情况，一方面大幅降低版权保护的成本，更为有价值的是，公司因此大大降低了客户获取成本以及通过大数据获取客户的内容需求数据。
![](/images/vgc/vgc 不敢配图.jpg)
 “鹰眼技术”对于公司商业模式中的维权部分，起到了极其重要的作用。说到这里，大家其实可能会很好奇，这个“鹰眼”到底是个啥技术。在一番搜寻后，找到了一些资料：“鹰眼技术”在其公司的年报里，正式名称是“互联网图片深度标引及侵权追踪技术”。在检索更多细节无果之后，数据挖掘、机器学习工程师尝试从以往经验出发，给大伙儿构建一套自己的“鹰眼系统”。
爬虫技术网上有很多，这里不展开讲。基础的爬虫通过一些浏览器插件即可实现，高级一些的用 python 包也能实现，当然这里面也是一门很大的学问，深钻起来可以写很多。本文主要讲讲这套图像检索对比系统，试图重构它。
首先要复习一下基础知识。在大学课程中，有一门课叫《机器视觉》。这门课将机器视觉相关的内容分为了三个层次：图像处理、图像分析及图像理解。图像处理主要是对图像的基础信息进行调节，不涉及高层抽象的东西。主要是均衡化、时域空域的各种滤波、图像编码等内容。目的是得到想要的图片。通俗来来讲就是用各种操作，到达类似 PS 的效果。第二个层次是图像分析，图像分析和图像处理有部分重叠。通过一些算子公式，对图像进行提取分析，以得到想要的数据。而第三个层次的图像理解，则是针对高层的抽象，基于图像处理的结果和图像分析的数据，进行内容的理解提取。
![](/images/vgc/vgc 图像工程与相关学科领域的联系与区别.jpg)
基于此，可以从两个维度进行建模。一个是传统的图像视觉；另一个则是新兴的模式识别、深度学习算法。
首先思考下，如果是一个人，他会如何判断两张图相似。从构图元素，从色彩出发？不，我会右键，单击属性进行查看，对比两者的基本信息。大伙儿不要以为图片就是单纯的图，其中可以存储很多信息。创建时间、创建者、修改时间这些大部分都会存储下来。前段时间还流行在图片后门存种子文件，都是类似的道理。
从图片的基础信息提取，是一个不可忽略的角度。很多时候，会忘记从问题的原始目的出发，转而用些花哨的解法，其实是不划算的。还记得那个用电风扇吹空肥皂壳的故事吗？这样的事情在模型领域也有不少。但也要知道，在这个问题上，图片的基础信息，也不是最完备的解法，仍需要一些更高级的手段。
第一个角度，从传统手法出发，对图像信息进行提取。学过这个的朋友，可能会知道冈萨雷斯的 Matlab 机器视觉，抑或是 OpenCV 处理图像。最简单的是对图像的颜色直方图📊进行对比。但是也样会带来较大偏差。抑或是两幅大小相同的图相减。但这样也会因为变换而产生偏差。比较高级的、常用的手法是提取算子，角点特征去提取他。提取后再进行对比。但这个方案也会有问题🤨，效率比较低。要拿库里的数万张图去匹配互联网上新上传的200万张图，计算量巨大。没准这也给部分群众，公司在“放长线钓大鱼”的错觉。也许只是系统真的太慢了而已。
而更近一步的，可以考虑用模式识别的方式去处理它。通过现有成熟的技术，将图像转化成向量，做向量之前的计算。这样的好处是可以利用 GPU 释放算力，同时对于图片的二次加工，如旋转、剪裁、翻转、加滤镜等可以起到很好的识别作用。为了提高计算速度，可以考虑对向量表征进行编码，然后利用文本检索的技术，去做一个倒排索引。更进一步的，可以通过识别图片的意思，讲图片的主体描述出来。这样的图片一般都是描述重大社会事件的，具有较好的识别度。这里可以参考之前写的文章：教 AI 学会看图说话：Image Caption。
总体来说，实际的架构可以是以上的综合。爬取公开互联网上的图片，并存下原始链接和页面快照，以便日后确认。讲爬下来的数据进行处理，将之与库中的图片对比（当然库中的图片也可能是爬下来先收录再谈）。对比返回一个相似度，100%重的那就是的了，接下来就是法务维权。
这套系统的核心，其实不是人工智能，人工智能只是一个技术手段。你用“人工”去对比互联网上的每一条资讯的图片，也能达到这样的目的。当然，也不可否认其助推作用。其中最让股民喜欢，潜在合作方厌恶的，以至于这次反应这么大，大概是其稳固的维权式商业模式。
最后需要重申一点：以上资料均为历史经验积累，绝无视觉中国的半点内部资料，如有雷同，纯属巧合。
附录 视觉中国图片侵权追踪系统曝光：鹰眼系统
2018年度市科委第四季度项目(课题)验收公开清单
视觉（中国）文化发展股份有限公司 2016 年年度报告
《数字信号与图像处理》 &amp;ndash; 郑方， 章毓晋
《基于内容的图象和视频检索》</description>
    </item>
    
  </channel>
</rss>
