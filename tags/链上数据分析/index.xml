<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>链上数据分析 on 谷粒的博客</title>
    <link>https://kuhung.me/tags/%E9%93%BE%E4%B8%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</link>
    <description>Recent content in 链上数据分析 on 谷粒的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 03 Dec 2025 15:21:47 +0800</lastBuildDate><atom:link href="https://kuhung.me/tags/%E9%93%BE%E4%B8%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>链上数据挖掘导读（onchain data mining 101）</title>
      <link>https://kuhung.me/2025/data-mining-onchain/</link>
      <pubDate>Wed, 03 Dec 2025 15:21:47 +0800</pubDate>
      
      <guid>https://kuhung.me/2025/data-mining-onchain/</guid>
      <description>Web3目前已是一个既定的事实，融入到现有的金融体系之中。围绕Web3、特别是链上数据的服务，也越发成熟。一般意义上的数据挖掘、数据分析，也适用于链上。因为链上的数据是公开的，所以一般人也能获取。
你是否也好奇，链上的巨鲸用户是如何被发现的、关于比特币的各类指数，是如何计算的。这篇文章，就用来回答链上数据挖掘的基本前置信息。看完本文，你将对链上数据挖掘，有一个基本的认知，并可以通过文末的Github链接，动手实操。
接下来，我们按照数据定义、数据获取、数据加工、数据应用四层思路，一起来看看链上数据。
链上数据 说到链上数据，这里有两个概念需要澄清。首先，交易所的k线、各个矿池的价格数据，不算严格意义上的链上数据，但他也是链交易的一环，所以下文也会提及。接着便是真正的区块链上存储的数据，它是严格意义上的链上数据。
下图是使用 CoinGecko API 获取近90天比特币价格数据的例子：
而在区块链上，数据会分为三类。他们分别是交易数据，包含收发地址、转账金额、余额信息；区块数据，包含时间戳、矿工费、矿工奖励等；智能合约代码，区块上的编码业务逻辑。我们主要关注交易数据。
当然，围绕区块链，类似证券交易，还会有各类研究报告、以及社媒数据。这两个，不在今天的讨论范畴。
数据获取 就目前来说，单一链的数据量已经膨胀的非常大了，特别是主流的比特币、以太坊等。你可以下载整个区块链到本地，但这并非最佳选择。两年前，受序数（ordinals）活动影响，完整的未修剪的比特币区块已经有600G大小。
不过也别担心，我们有公链浏览器这么个东西。通过它，可以查询链上的交易、地址和合约情况。在文末的链接中，有一个使用 Etherscan 查询以太坊创始人 Vitalik 地址的例子。可以看到如下返回：
另外，即使是原始的数据，也并不能直接用来分析。需要加工和存储。有平台对数据进行了加工处理，导入到了关系型数据库中。其中的典型代表就有 Dune Analytics 这类。我们可以直接在平台使用SQL进行查询，随后可以通过API获取相应数据。
下图是通过Dune查询并返回以太坊每日交易数的一个例子
此外，在区块之外，还在存在尚未被矿工验证的代替确认交易合集。对其的分析，能够有效评估区块链网络的实际使用和健康状态，也能通过其推断市场预期、优化交易费用。此外，还能发现热门的新Token。下图是使用 GeckoTerminal 获取以太坊热门DEX交易池的例子。
数据加工 这里的数据加工，也分为两个层面。因为前面有提到，有些工具会预先处理数据，形成数据库。但实际上，你也一定会好奇，他们处理了哪些数据。数据加工，这里分为数据清洗和数据再加工两个层面。
在数据清洗层面，原始区块字段，包含很多对于下游分析无用的信息，特别是非交易活动。比如交易所新造币转移给矿工、或者一些排除找零（change outputs）以及一些排除重复的程序化行为。这些行为，一般在我们使用加工后的数据时，无需考虑。
而真正对我们重要的是，数据再加工。一般这个活动，去取决于我们的分析目标。比如我们想要构建交易图，那么就需要把上一步数据中涉及的节点和边提取出来，构建有向图。比如我们想要构建巨鲸监控，则我们需要按交易地址进行处理归类，汇总同一地址或同一实体的交易。
数据应用 就一般用户来说，数据应用无非是能不能帮他挣到钱。这里可以分为前期的价值评估和日常跟踪跟随。价值评估会有几个常用指标：
◦ MVRV 比率 (Market Value to Realized Value)： 市值与已实现价值的比率，用于判断资产价格是被高估还是低估。
◦ NVT 比率 (Network Value to Transactions)： 将网络价值（市值）与交易量进行比较，类似传统金融的市盈率 (P/E)。
◦ CDD (Coin Days Destroyed)： 币天销毁，衡量长期持有的币被移动（卖出）的程度，用于判断长期持有者的动向。
◦ SOPR (Spent Output Profit Ratio)： 卖出产出利润率，衡量市场参与者在卖出时是盈利还是亏损。
下图是一个比特币价格移动平均线与MVRV比率的数据图：
日常的跟踪跟随，见的比较多的便是聪明钱跟踪和巨鲸钱包的监控。下图是已知的部分巨鲸列表：
◦ Smart Money 追踪： 追踪 Nansen 标记的“聪明钱”地址的持仓动向，这些地址的行为映射着信息差，比如内幕交易。</description>
    </item>
    
  </channel>
</rss>
