<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>交付 on 谷粒的博客</title>
    <link>https://kuhungio.me/tags/%E4%BA%A4%E4%BB%98/</link>
    <description>Recent content in 交付 on 谷粒的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 17 May 2023 21:38:16 +0800</lastBuildDate><atom:link href="https://kuhungio.me/tags/%E4%BA%A4%E4%BB%98/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>全面了解 PrivateGPT：中文技巧和功能实测</title>
      <link>https://kuhungio.me/2023/privategpt/</link>
      <pubDate>Wed, 17 May 2023 21:38:16 +0800</pubDate>
      
      <guid>https://kuhungio.me/2023/privategpt/</guid>
      <description>近日，GitHub上开源了privateGPT，声称能够断网的情况下，借助GPT和文档进行交互。这一场景对于大语言模型来说，意义重大。因为很多公司或者个人的资料，无论是出于数据安全还是隐私的考量，是不方便联网的。为此，我也进行了些许体验，跑完了整个流程，希望给读者朋友一些有用信息。
原作仓库地址：https://github.com/imartinez/privateGPT
先说结论：可用，但还有进步空间。特别是对于简单询问语句，该模型不像ChatGPT回答有来有回，而是提供若干可能性进行回答。而数据预处理环节的容错性、embedding向量的生成方法以及大语言模型的基底模型，每一个环节的质量都会影响最终的使用体验。可期待的是，每一个环节都有可能逐步改善，并最终带来质的飞跃。
原理解析 这套方法使用了 LangChain, GPT4All, LlamaCpp, Chroma and SentenceTransformers.
LangChain 用来生成文本向量，Chroma 存储向量。GPT4All、LlamaCpp用来理解问题，匹配答案。基本原理是：问题到来，向量化。检索语料中的向量，给到最相似的原始语料。语料塞给大语言模型，模型回答问题。基本原理和chatpdf没大差别。
环境配置复现 首先是环境，后文采用的是ubuntu环境。mac环境也能支持，不过在安装过程中需要调整部分参数。家里有ubuntu系统，图省事就用它了。
conda create -n gpt python=3.10 # 其他python版本不行，后续有个3.10的语法糖 conda activate gpt pip install -r requirements.txt 配置环境
cp example.env .env vi .env 具体配置如下
PERSIST_DIRECTORY=db MODEL_TYPE=GPT4All MODEL_PATH=models/ggml-gpt4all-j-v1.3-groovy.bin EMBEDDINGS_MODEL_NAME=all-MiniLM-L6-v2 MODEL_N_CTX=1000 下载资料与模型权重
我们以《Generative Agents: Interactive Simulacra of Human Behavior》AI小镇这篇论文为例：
cd source_documents curl -o x.pdf https://arxiv.org/pdf/2304.03442.pdf cd .. mkdir models cd models curl -o ggml-gpt4all-j-v1.3-groovy.bin https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin 向量化数据
python ingest.py 如果502失败，可以尝试shell中直接调起python，输入下面的代码。下载完成后退出。</description>
    </item>
    
    <item>
      <title>ChatGPT 现状回顾与机会分析</title>
      <link>https://kuhungio.me/2023/chatgpt/</link>
      <pubDate>Tue, 14 Mar 2023 00:41:03 +0800</pubDate>
      
      <guid>https://kuhungio.me/2023/chatgpt/</guid>
      <description>前言 最近中文互联网上最火热的莫过于ChatGPT。人们都在谈论这个东西是多么“划时代”的产物。过去对AI不成气候的论调也看不见了，主流媒体似乎都在说：牛。不少大厂说自己也要“下海”参与布局与竞争，即使他们才不久刚ALL in 元宇宙。AIGC似乎是PGC、UGC的下一个大蛋糕。
该技术在22年11月底就推出了，但并未在当时引起太多关注（当然也和大家都急着囤药有关）。去年十二月份左右，即有技术论坛谈论到此事。不过大家讨论的并非它有多牛，而是关注的它带来了多少“垃圾内容”。新的“内容农场”的论调随处可见：假话空话以及语义不明的文本内容占据高的SEO，污染各种可见的搜索结果。Stack Overflow发表声明称：将会拒绝这类生成的答案在论坛中出现。随后，更多论坛也发表了类似的声明。
谁可想，三个月不到，该产品便火爆中文互联网出圈。
回顾 就像是各类引爆点事件一样，你永远无法准确预测哪些事情会被广泛传播，只能事后诸葛亮分析一波。从最快达到1亿用户数的产品；到谷歌下场表演失利，市值蒸发。这类资讯，前者挑动大众市场，后者让各类科技公司如坐针毡。在“营销”传播方面，赚足了眼球。
产品设计上也不输。如果从游戏的视角来说，ChatGPT其实是提供了足够多的可玩性。无论是用户的可玩性，还是开发者的可玩性。用户可以问各种想到的问题，还可以和它做角色扮演游戏。开发者能够很轻易地就API接口进行二次开发，满足特定领域的需求。足够好玩+确实有用，是其核心竞争力。
解读 在19年我还写过一篇关于它的文章，通过GPT-2生成文章。但当时，它的能力还有限，只能生成语义看起来连续，但却一眼假的“胡编”文体。后来大家发现用固定规则也能生成类似的话。一度衍生出了狗屁不通文章生成器等产品。规则、或者说正则在垂直领域确实效果显著。维护简单，还能满足模型可解释性要求，满足确定性。其实现在，ChatGPT的接口中仍然可能存在不少规则，特别是涉及有争议的话题或者是时间感知等话题。
在没有细致体验之前，我对它的理解，也不过是GPT-2的加强版。或者是Siri和小冰。但体验之后，我发现它的体验真可以称得上是：令用户惊奇+满意。无论是对话流畅度和语义衔接程度，还是说内容的有效性。可以不夸张的说：仿佛回到了几岁的时候，站在一台拨号上网的计算机面前，无限可能等着我去开启。
GPT 全称 Generative Pre-Training，生成式预训练模型。生成式通过对数据的联合分布建模，与之对应的是判别式，采用条件概率建模。预训练通俗来讲是大模型训练，然后在垂直数据上进行微调。方式一般是冻结神经网络的前n-2层，只对n-1进行权重调整。以计算机视觉举个例子，我们在大模型的权重基础上，仍能够通过微调让模型认识猫狗，即使猫狗不在数据集中，猫狗的数据集量级远小于大模型。
据公开资料显示，ChatGPT用到的技术其实不复杂，甚至是前面大厂开源的东西。怼大规模数据+大模型，然后加上PPO强化学习。但是就这样它却有出色的表现，特别是在多轮对话方面。常见的NLP任务，这个模型通过对话都能实现。无论是情感分类、语言检测或是翻译任务、改写任务、摘要任务、总结任务、续写任务，甚至生成任务它都表现良好。
机会 谈机会总是离不开股市“投机”，因为股市是经济的晴雨伞，也是市场的热点所在。在春节期间，我的某大厂同事便提到了他们内部在all in这个方面。当时我还没当回事，认为不过是互卷的新噱头。但没想到的是，确实有不少人在这其中获得了较大的alpha超额收益。
有人通过卖账号小赚一笔，也有人通过二次开发得到流量。大部分都淹没在人流中，小部分被广泛传播。借助其多语言特性，开发者能方便地开发一款产品，然后在全球传播。开发出来翻译工具、pdf解读工具。翻译本身其实和调用谷歌的翻译流程上无二，但也获得不少曝光。
但很快，人们也发现ChatGPT会编故事。ChatGPT不会说不知道，而是尽量从概率空间生成有含义的对话，即使这含义本身，并无对应实体。当你问一本书或者一首歌的相关信息时，它总是会“移花接木”，让人摸不着头脑。当然，你要拿去问文献，也只会生成一批其他宇宙才可能存在的文章。
但这也是人类的特点，不是吗？只要语气足够肯定，三人即可成虎。所以，在它扮演解梦角色、扮演星盘角色时，大家也不会苛责它效果不稳定。因为它本身也符合了人类的自我归因认知和自我暗示。
展望 对于大部分企业来说，“自主研发”一套ChatGPT并不划算，更多还是利用API的接口能力。但当前有个问题亟待解决，如何将企业独有的小规模语料的并入大模型中。在写稿子的同时，据悉GPT-4即将发布。其具备多模态能力，跨越语言、图片和视频。如果支持自定义语料的话，可以预见三大运营商以及银行的客服系统将有巨大体验上的升级。
虽然它有如此多的功能，但还是有上手成本。特别是在一些复杂任务场景，需要提示词去引导它。为此还专门衍生出了一个专有名词：prompt engineering。
提示词的本质，和搜索词类似，即“提问的艺术“。不同的是搜索引擎用更长的框暗示你填更多的词，以此来获得更多的信息。提示词却更为复杂，一长串的指令只为对方扮演正确的角色或者绕过特定的限制。为此，我也写了一个网页版的提示词查找器，方便初次接触的朋友体验到进阶玩法。地址：https://kuhungio.me/awesome-prompt-engineering/ 。其具备基本的提示功能，随机出现一组，复制方便。
真人在你面前，你都可能不会如此耐心。面对一个机器人，人们却有充足的耐心和多样的方法去提示它。
回到一开始人们的担心。在人工智能领域，人们常说的一句话是：garbage in, garbage out。用来形象说明数据质量的重要性。随着这个工具的普及，公开互联网上的数据分布，将不可避免受到影响，反过来又作用到模型本身。可以预见的是：能从繁杂的信息中获得关键信息，以批判视角看待问题，能更好组织和表达语言的人，将在未来越发稀少和可贵。
关于作者</description>
    </item>
    
  </channel>
</rss>
