<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on 谷粒的博客</title>
    <link>https://kuhung.me/tags/ai/</link>
    <description>Recent content in AI on 谷粒的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 07 Oct 2025 21:12:32 +0800</lastBuildDate><atom:link href="https://kuhung.me/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI相亲小镇开发纪要（三）</title>
      <link>https://kuhung.me/2025/love-in-ai-town-3/</link>
      <pubDate>Tue, 07 Oct 2025 21:12:32 +0800</pubDate>
      
      <guid>https://kuhung.me/2025/love-in-ai-town-3/</guid>
      <description>产品在发布后，受到了大家的广泛喜欢（不是）。为了增加真人感，主播增加了真人数据投放。第一个Agent 智能体是 UP主本身，ENFJ 投放到了小镇中，验证结果符合预期。Agent最后匹配的人选，也是主播在现实会有好感的人。
接着，内测群也发起了测试。累计招募了3位真人朋友。从测试的结果来看，也是合乎预期。最直接的证明就是，这三位即使身份背景不同，都对UP主的Agent表达出兴趣。这和他们选择参加游戏的现实结果一致。
不过，更多的用户停在了门外。根据用户访谈，有朋友认为该项目的定位和商业BP不够清晰。所以，第三次迭代纪要，主体便是回应这个问题。
这个项目的发起动机，是UP主本身有交友的需求。但在测试过程中，发现很多社交应用，都缺乏促成成交的机制。就像网友所说，社交APP的核心指标在于消费。没错，是用户在平台上各类消费活动。包括但不限于：知道谁喜欢了我、让对方直接看到我等更多特权。
为了让这个消费循环起来，平台强调的是下一个更好，而不是告诉你这个不错，好好接触。而你则需要尽量打扮、包装自己，才有机会被打上优质用户的标签，成为平台的“展示商品”。对于这样的展示品，平台自然是不想让其流失。
这不是发展亲密关系的正确方式。我们排除掉那些只是想玩一玩的人，剩下的人在社交APP上，实际上希望找到合适的对象，建立长期亲密关系。而非在不同的人身上辗转，让自己处于似乎丰富（候选人），但实际匮乏（建立深度连接）的状态。
以下是一些重要QA。
Q：产品的核心人群和定位？
A：核心定位在于一线城市，互联网大厂相亲交友、适婚年龄匹配。为什么是这个核心，因为up主的主要人脉在此。后续可能会考虑扩大，但核心一定是从这里开始。
Q：产品和专职红娘的中介公司的区别？
产品的核心仍然是撮合服务。更多借助AI模型去匹配。设定清楚过程，减少人的主观干扰。也即是说，我们的模拟匹配，过程可溯源、可追踪。同时也减少了用户反复开场的重复枯燥感。
Q：做这件事的初心？
市场太菜，社交APP的商业模式定位就在于反复收取各类费用，是消费而不是撮合。大部分用户处于沉寂、低曝光状态，而平台将曝光设置为付费点。
Q：算法在其中的作用？
A：人不用聊，直接让AI帮你聊；算法匹配打分，更精准更懂你。
Q：行业洞察情况如何，数据情况？
A：目前从身边感受来说，普遍存在需求。这部分数据后续陆续补充。
此外，我们再过一遍技术细节。本地迭代，实现两个核心功能。
一个是将LLM模型从本地机器，迁移到UP主更适合做模型服务的Linux服务器。另一个是增加了摄像头，使得我们能够在屏幕上跟踪对应agent，能够掌握它的第一手行为动作。另外一些小的改进，是数据采集增加了问卷，不用通过对话收集信息了。
最后，有这部分需求的小伙伴可以持续关注本项目，更大规模测试计划中。
关于作者</description>
    </item>
    
    <item>
      <title>AI相亲小镇开发纪要（二）</title>
      <link>https://kuhung.me/2025/love-in-ai-town-2/</link>
      <pubDate>Sat, 27 Sep 2025 15:55:13 +0800</pubDate>
      
      <guid>https://kuhung.me/2025/love-in-ai-town-2/</guid>
      <description>进入开发 书接上回，我们根据现有的资源，结合自身的优势和兴趣点，决定在相亲这个双边市场，进行撮合服务。
工具载体是我们的AI 小镇。基本思想是：数据化自身标签，设定目标，剩下的交给AI。减少相亲交友的重复和倦怠，提高匹配效率。
AI小镇有自己的一套代码，需要做的事是在原来的基础上进行调整。其核心功能，配置标签、设定目标为现成功能。LLM驱动的逻辑也是现成的，整体一次性能投放8个角色。
首先要做的是保证启动，实现原代码的功能。过程略微枯燥，总之就是发现问题，理解问题，寻找解决方案，尝试解决方案，最后修复。
在本次的案例里，复现最大的问题是后端部署方式，需要调整为本地部署。这些内容可以在up的视频中看到，不在此赘述。
本地化 跑通之后，接着要做的是本地化，以符合需求。我将其分为两部分。第一步是泛功能的本地化，另一方面是针对本项目的本地化。
泛功能方面，包括语言本地化、交互的调整。中文本地化，包含提示词和初始化角色。删除一些没必要的提示词，屏蔽掉移动端逻辑。
之前的代码，侧重demo宣传，有较多品牌logo植入。另外核心可视区域较小。up放大了主体窗口，缩小并调整了交互组建的位置，删除无关的品牌宣传logo。
这些在编程辅助工具帮助下，一个工作日就能完成。
项目的本地化，关注的是项目目标。首先我们的撮合服务，不能偏离现有用户习惯太多。也要有其他产品、服务具备的标签服务。这些标签，成为系统筛选的依据。
其次，以LLM为核心的交互，需要做对应调整。好在这个项目原始代码逻辑也不复杂，调整对应的提示词，强调匹配的目标，并且需要利用前面的标签，即可初步达到目的。
再者，我们借鉴游戏设计，引入经济系统。在这里是好感系统。Agent需要通过自己的努力，提升意向对象的好感度。Agent之间的对话，会影响好感度。这样就将经济目标，与核心功能绑定。
在我们没做改动之前，这个项目内的各个Agent目标是分散的。调整后，Agent的行为逻辑，更符合国内文化。初步注入的8个Agent，在各自交友目标的驱动下，和剩下的7位反复交谈，最后反应在好感度上。
作为系统的管理员，只需要录入客户的Agent信息，收集最后的好感度，即可筛选出匹配的对象。整个过程可视。
其他展望 调整之后，仍有很多待优化的项目。比如提示词、循环系统、外部资源消耗监控。商业行为，需要控制完美主义倾向。完成比完美重要，先交付再优化。
提示词方面，原项目差不多构建于2年前。那时基座模型的性能还差点儿意思，提示词方面也没有系统的方法论。现在提示词经过不少讨论迭代，已经形成一些写法套路。
整个项目在Agent 设计中，ReAct（推理与行动）使用得很粗糙。仅针对对话结果进行了打分分析，并不涉及下一步行动策略的调整。在现实中，这恰恰是人类最常用的。
项目依赖本地的大模型，但并未对token的消耗进行统计、未对服务的负载情况进行监控。若服务不可用或性能下降，实际会影响对话部分的质量。
目前，项目的演示视频已发布到多个平台，获得的曝光仍较为局限。获客是最大的挑战、缺少话题性，难以获得垂直流量。
看到这里的朋友，动动手指，填写一分钟问卷，圆你的交友梦。限时免费匹配，定期直播结果。https://wj.qq.com/s2/24050706/c5d5/
关于作者</description>
    </item>
    
    <item>
      <title>AI相亲小镇开发纪要（一）</title>
      <link>https://kuhung.me/2025/love-in-ai-town-1/</link>
      <pubDate>Tue, 23 Sep 2025 08:30:15 +0800</pubDate>
      
      <guid>https://kuhung.me/2025/love-in-ai-town-1/</guid>
      <description>开发背景 玩过社交软件的朋友都知道，软件交友体验不佳。这其实来源于目的的背离。平台的目的是留存和付费，用户的目的是匹配离开。尽管不少平台在努力平衡，但仍会看见许多精心设计的付费点；许多暗示你下一个更好的引导。
优质的用户是平台资产，当他们匹配成功时，意味着平台的资产流失。
除开目的的背离，还有客服感。不少网友反馈，在社交软件上聊天像是客服，对不同的人要重复相同的话术，聊着聊着对方还会断线。这种感受在消磨人的耐心，消磨对美好爱情的憧憬。
用户需要填写标签。例如学历、资产情况等。这些标签化的筛选方式，早已植入到了人的内心。品格无法量化，便先通过标签筛选。而一个人的偏好，基本是固定的。
这些重复的沟通、模式固定的筛选，完全适合AI agent来做。AI 可以重复沟通、能接受对方的掉线而不感到倦怠。AI也不会有下一个更好的期待，它做的是忠实于人的指令。这才是AI该做的事情。
技术选型 好吧，其实是拿着锤子找钉子。港科大让AI小镇又火了一把。博主秉着好奇的心理，找到了这个项目开源代码。尝试复现，增加附加值。
上周的家庭会议上，博主怂恿老爸搞月老做个副业。毕竟我的叽叽喳喳、反复唠叨是遗传的他。这个活很适合他，也很适合我。博主是ENFJ，大剑人格。有价值观追求，又能察觉到其他人的情绪。
一线大厂人群的相亲交友需求存在，且没有SOTA解决方案。AI小镇，是一个现成框架。做原型验证，在其基础上进行调整就够了。
由于启动资金有限，考虑到宣发效果受制于流量平台（受制于买量），实现思路是本地运行agent服务。这有两个好处。
一方面节省功能开发的时间和成本，登陆、存储、鉴权都需要大量的开发和测试时间。上线后，计算使用外部大模型API，消耗不可控。本地不会有这样的困扰，只管把机子跑满就是。
缺点是用户需要一一维系。也是优点，保证用户真实。
另一方面是，博主的目标是构建撮合服务。agent是其中的工具，人才是目的。不追求规模化，但追求有效传播、能切实帮助到客户。本地运行还能通过录屏解说，实现二次传播。
竞争态势 竞品方面，博主用gemini的深度搜索做了调研。他返回的类似产品，都集中在AI 情感陪伴方面。和本产品的定位不同。
社交媒体上，也存在情感、相亲题材的博主。他们的粉丝数大致是数万，风格在于择偶定位和线下活动。据称头部某团队，6人达到千万年营收。
其他一些更本地化的中介平台，其变现方式为会员费。有用户表示红娘逼单和伪造见面对象的情况较多。
定位与风险 AI相亲小镇解决匹配效率的问题。替代低效、上瘾、增强用户粘性的筛选行为。减少反复开场的倦怠感。减少下一个更好的期待感。通过算法进行条件匹配和对话沟通，实现高效、精准的双向匹配。
参与者将自身数字化，拟定标签、设定目标，剩下的就交给AI agent。这种第三方的视角，让参与者有机会跳脱出来，意识到自己真正想要的是什么。
本产品的主要营收方式为数字化服务费，主要成本为算力和人力支出。
本产品无法完全杜绝资料作假、美化，无法帮助提升外在美商，无法帮助用户实现特定功利想法。
本产品的主要风险来自于市场宣发，双边市场缺乏足够多的参与者。无人感兴趣，冷启动失败。
关于作者</description>
    </item>
    
    <item>
      <title>从2015到2025：技术创业的变与不变</title>
      <link>https://kuhung.me/2025/build-in-2015/</link>
      <pubDate>Mon, 25 Aug 2025 17:43:46 +0800</pubDate>
      
      <guid>https://kuhung.me/2025/build-in-2015/</guid>
      <description>在历史的长河中，我们总能发现那些令人艳羡的“先机”——无论是2008年购入比特币，2012年加入字节跳动，亦或是2015年买房置业，2018年重仓英伟达。然而，这些所谓的“机会”往往是幸存者偏差的产物。即便时光倒流，个体也未必能做出相同的决策，更遑论那些未能浮现的无数可能性。真正的洞察，需站在彼时彼刻，而非依赖于今日的“后视镜”视角。
创业亦然。本篇文章将以《技术人创业攻略》为引，回顾并剖析2012至2015年大众创业浪潮中技术人的心路与实践。十年光阴流转，那些昔日的观点与抉择，如今已成为检验其真实价值的试金石。因为，评判一个人，不仅要听其言，更要观其行。
那些要完蛋的公司 在《技术人创业攻略》中，不乏有创业者对当时的大公司（如微软、Adobe）提出尖锐批判，预言其将因臃肿而走向衰落，小公司则将迎来颠覆性时刻。然而，时至今日，我们回望十年，这些“即将完蛋”的巨头不仅未曾陨落，反而凭借其庞大的规模优势，更上层楼。
这种创业公司打破大公司垄断，实现颠覆式创新的故事，总是很受欢迎。在故事里，大公司是邪恶的，忘记初心，垂垂朽木的。创业公司是锐意进取，机动灵活，能够快速吃下这个新的市场的，勇者斗恶龙。
从我的个人从业经验来看，即使一个大公司内部有多少的弊端，部门墙、裙带关系、决策迟缓，人员流失高，缺乏有效的接班人培养制度，他仍然会在自身的规模优势下，存活数年。这里的规模优势，有可能是资金流优势，也可能是粉丝基础。
所以，如果你的目标是颠覆谁谁谁，那大概率无法如愿。这些大公司不会完蛋，反而会在官僚系统下，存在更久。虽然这个官僚，可能会让其中的员工很难受，会溢出更多的创业者，来挑战这个公司本身。
那些反复炒作的热点 今天，做投资的如果没有接触过AI硬件，那ta大概率不是一个合格的投资人。在24、25年，大量的目光集中在了AI硬件，特别是AI陪伴硬件上面。令人玩味的是，回望14、15年，当时的热点里，也有硬件。除了硬件，还有云计算这个老伙伴。
大家在两个阶段的反应都是类似的。**硬件搭配当时的热门。15年是互联网+，热炒IoT概念；25年是以LLM为代表的AI技术。**他们可能之前都没接触过硬件，是做运营、做建材等等其他行业的人。涌入了大量新晋创业者。
关于硬件创业，我们从今天回头来看，能跑出来的创业公司也寥寥无几。除开当下因为汽车而风头正盛的小米，大部分硬件公司都消失不见，或是被大厂吸收合并。当时在硅谷，Nest这家引领风尚的硬件公司，后来也被谷歌收购。
创业者应谨慎入局硬件。因为它有实体，那么就需要仓储、物流，需要资金垫压，影响资金周转。其次，硬件涉及的元器件众多，需要极强的供应链管理能力。再者就是面临抄版风险，华强北拿到你的产品，短时间就能复制出同款且价格更低。最后很关键的一点是：硬件利润率低，商业模式存疑。除非做到苹果这种程度，年年出新，且搭配软件服务。
那些不变的术与道 这本书包含很多技术人的观点。这些观点覆盖了团队建设、个人品牌，这些软技能不管在哪里都很重要。也包括创业早期的一些方向心得，是非常宝贵的经验教训。
虽然很多产品的竞争优势并不完全在研发，但是也应对研发心存敬畏。研发团队，需要有共同的价值观、关注软件质量，并以开放的眼界看待新技术。通过开源项目、做内容输出来建立个人品牌，获取更多机会。虽然大公司都有限制员工的自我表达，技术人员应该利用自身的技术优势，把握住这些能促进个人成长和扩展合作的机会。
创业会面临资金短缺和方向迷茫，坚持不懈、快速试错是成功的关键。一个可衡量、可规模化的方向是好方向；追求用户体验，在做大平台前应聚焦用户。在团队和管理方面，配置合理的股权关系，招募合适的人才，注重团队的合作精神和敏捷管理的基础功。
那些有意思的观点 这些创业者里面，有几位同行（或者说曾经是）。其主攻方向在数据挖掘、算法方向。
其中一位创业的方向是数据库、大数据方向。他认为数据挖掘在办公室政治下面没有生存空间，人不喜欢机器做决策。这点和我的体会有些许相似。大公司里面的数据分析、数据推动决策，更多是理论上。太多不可控的算法之外的部分，会消磨一个人的耐心和对专业的热情。
而另一位做无人车的，他出来创业的动机理由是：不想做公司中的重要积木，被其他积木挤压。他想做一个自由的变形金钢。他对算法的理解也十分到位，数据是算法的瓶颈。这种创业者的成功几率，要比那些看到技术PR稿就嗨起来的人强很多。
还有一位创业者，他和自己的合作人产生了分歧。他认为应该投入更多的人力和金钱到产品研发上面去。而他的合作人则热衷于炒房。要知道，那个时候可是2011年前后。如果炒房能坚持下来，想必一定比这位创业者生活更滋润吧。
那些可能偏颇的总结 整本书采访了不少技术人，也采访了不少“组局”做平台的人。当一个方向热起来的时候，总是少不了组局的人。如今，AI大热且门槛降低的情况下，这类人只多不少。从长期来看，这种面向开发者和创业者的运营活动，缺乏清晰的商业模式，受投资周期影响巨大。
其中也有不少对于技术抱有不切实际幻想的创业者。他们的特点是并未躬身亲行，且相对自负；容易被一些宏观叙事忽悠。这点和我之前一个朋友类似：他认为Agent是当下的热点机会。但当你问他你写过demo吗，他只会说没有。他会说中国有制造优势、有人才红利，能赢。但遗憾的是，这个优势是系统优势，并非个人优势。不应忽视系统内竞争。
总体来说，这本书的成书质量还算可以。能相对还原当时大家的想法，不像现在采访稿一大部分是PR稿，缺乏真诚味。
正像认知的那样，创业乃九死一生。书中现在还存在的公司，十不足一。即使这般，现在还是有不少人入场。一些人是天生的冒险家，敏锐察觉每一个风口，并一头扎入其中；也有些人是从长远出发，与其排队晋升，不如在外闯荡验证实力；还有一些人，是带着预算和DDL，验证想法不留遗憾。
回望过去，不是为了捕捉下一个风口，而是为了理解商业和人性的不变规律，从而更好地应对未来的不确定性。真正的创业者，是在理解周期与人性之后，依然选择脚踏实地、验证自我的人。
敬每位脚踏实地的创业者，这一路并不容易。
关于作者</description>
    </item>
    
    <item>
      <title>41个 LangChain / LangGraph / LangSmith 案例研究</title>
      <link>https://kuhung.me/2025/agent-case-studies/</link>
      <pubDate>Mon, 21 Jul 2025 21:48:52 +0800</pubDate>
      
      <guid>https://kuhung.me/2025/agent-case-studies/</guid>
      <description>关于作者</description>
    </item>
    
    <item>
      <title>三大LLM厂商的提示词行动指南</title>
      <link>https://kuhung.me/2025/prompt-guide/</link>
      <pubDate>Sun, 20 Jul 2025 10:20:04 +0800</pubDate>
      
      <guid>https://kuhung.me/2025/prompt-guide/</guid>
      <description>提示词工程的演变与重要性 自从22年以来，提示词已经经过多轮的迭代，发展出了更系统的方法论。在初期，各路网上的提示词，还更多是角色扮演，偏向C端用户。大家也相信，凭借 LLM 基座大模型的进步，提示词会逐渐退出舞台。然而一坤年（两年半）过去了，期待的基座模型大进步并未出现——提示词仍然决定了 LLM 应用的质量；也决定了用户交互时，能多大程度得到自己想要的答案。因此，再探提示词是有必要。无论是个人使用，还是构建 LLM 应用，都需要掌握其基本原理和目前的最佳实践。
提示词技巧与人类沟通的共通性 产品设计本身也是人类社会规则设计的一个抽象。从宏观来说，提示词技巧和人类社会的一些常见共识重合度很高。例如：清晰阐明你的诉求、明确角色职责、分阶段分解任务、重复诉求以防止遗忘、约定清晰的输出结构、提供样例进行模仿、引导输出内容、要有事实数据支撑、设计指标反复迭代。这些技巧，在与人沟通、协作、领导、教练的时候，是非常重要的。靠意识同步的三体人，其 AI 的形态必与我们的不同。只要人类社会还是当前的结构形态，当下这些工作就还有意义。
提示词的分类 提示词，我们从配置方来说，分为三类。分别是系统提示词，由 LLM 提供商预设在模型 API 接口下，定义模型的行为准则。例如：反黄暴之类的。这一般是第一条注入的提示词。角色提示词，这个提示词是开放给用户配置的，比如配置为“你是一个大模型专家”。最后就是常见的用户交互提示词，用户输入的内容也算提示词。在此基础上，又根据用户和场景，派生出例如：指令提示词，指定输出xx字这种；上下文提示词，交代上下文说过啥；样本提示词，按照给的样式来；CoT 提示词，好好想想，逐步思考，等若干提示词种类。
主流大模型提供商的提示词建议 话归正题，笔者参考了 Anthropic、Google 以及 OpenAI 的提示词构建文档，力求从第一手信息源出来，结合自身的使用经验，给到当下最好的解决方案。这其中也离不开各类 LLM 支持构建的 deep reasearch 工具，这个过程才会变得更丝滑、效率更高。但由于人脑的带宽毕竟有限，错误和纰漏在所难免，读者朋友如有发现，欢迎指出。
Antropic 的提示词建议 以 Anthropic 为例，他们在训练过程中使用了大量的 XML 的结构化语料，因此类似的结构化提示词在他家的模型上会表现得很好。另外也强调清晰和直接的重要性。即清晰表达你的需求，可量化的提出你的诉求。而不是丢一个模棱两可的问题，然后反复沟通。但其实这部份也是需要的，这里更多是指大规模应用的时候，系统预设提示词，减少用户和下文的困惑度，这在软件系统中很重要。而且模型本身就是概率模型，它的结果是不确定的，那么反复沟通其实就有必要。
因为 LLM 的本质是预测下一个 token 是啥，所以可以通过预设这个开头来保证它会做出预期内的事情。比如想要输出 JSON，那么就以{开头。这一技术也被用在 deepseek 的 think 推理里面，通过预先提示来让模型进行 reason 推理。另一方面，由于模型的被奖励尽可能多的输出下一个 token，所以当遇到负面提示时：比如不要干啥，模型可能会产生意料之外的变化。因此，Anthropic 家的文档建议出更多的正面提示词：应该做什么，而不是不应该做什么，借此来减少不可控性。
Google 的提示词建议 而 Google 来说，对于他们的 Gemini 模型，则建议提供一个清晰可供参考的样本。这点在笔者做仓满量化相关的产出时，深有体会。只需要在开始和模型磨合，得到想要的代码模版或者是 doc 模版，后续只需要提供这个模版，即使是 Gemini-flash 模型，也能高效完成代码的编写工作。除此之外，谷歌文档中也给出了更高级的方式。例如 Step back 思考。先抽象，再解决问题。CoT 思维链也是一种方式，通过提示词注入“一步步思考”的方式，让模型的输出更具可解释性。
当然，还有像多次运行取平均值这种机器学习上的常用技巧（自洽性）。不过话说回来，这种方法对于成本控制和延迟响应要求蛮高。而在 agent 大行其道的当下，ReAct 也是一个重点。即推理和工具反馈相结合，用反馈来修正模型的表现。不过这些技术会显著增加 token 的消耗，需要在实践中取舍平衡。</description>
    </item>
    
  </channel>
</rss>
