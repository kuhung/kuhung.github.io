<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据挖掘/机器学习 on 谷粒的博客</title>
    <link>https://kuhungio.me/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 数据挖掘/机器学习 on 谷粒的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language><atom:link href="https://kuhungio.me/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Xgboost 三种特征重要性计算方法对比与扩展</title>
      <link>https://kuhungio.me/2021/three-feature-importances-in-xgb/</link>
      <pubDate>Mon, 08 Mar 2021 21:09:31 +0800</pubDate>
      
      <guid>https://kuhungio.me/2021/three-feature-importances-in-xgb/</guid>
      <description>简单描述 实际发布 最后一次修改 xgb 特征重要性计算方法及使用场景 2021-03-08 2021-03-09 特征重要性 作用与来源 特征重要性，我们一般用来观察不同特征的贡献度。排名靠前的，我们自然而然地认为，它是重要的。
这一思路，通常被用来做特征筛选。剔除贡献度不高的尾部特征，增强模型的鲁棒性的同时，起到特征降维的作用。
另一个方面，则是用来做模型的可解释性。我们期望的结果是：重要的特征是符合业务直觉的；符合业务直觉的特征排名靠前。
在实际操作中，我们一般用树模型的分类节点做文章。常用的就是 XGB 和其他一般树模型。
XGB 遇到的问题 XGB 很方便，不仅是比赛的大杀器，甚至贴心的内置了重要性函数。但在实际使用过程中，常常陷入迷思。
有如下几个点的顾虑：
这些特征重要性是如何计算得到的？ 为什么特征重要性不同？ 什么情况下采用何种特征重要性合适？ 今天我们就借这篇文章梳理一下。
XGB 中常用的三种特征重要性计算方法，以及它的使用场景。除此之外，再看两个第三方的特征重要性计算方法，跳出内置函数，思考其中的差异。
最后回到类似的树模型特征计算方法，进行特征重要性的一般方法总结。
以下场景非特殊说明，均针对 python 包体下的 xgb 和sklearn。
XGB 内置的三种特征重要性计算方法1 weight xgb.plot_importance 这是我们常用的绘制特征重要性的函数方法。其背后用到的贡献度计算方法为weight。
‘weight’ - the number of times a feature is used to split the data across all trees. 简单来说，就是在子树模型分裂时，用到的特征次数。这里计算的是所有的树。这个指标在R包里也被称为**frequency**2。
gain model.feature_importances_ 这是我们调用特征重要性数值时，用到的默认函数方法。其背后用到的贡献度计算方法为gain。
‘gain’ - the average gain across all splits the feature is used in.</description>
    </item>
    
    <item>
      <title>算法模型的可解释性</title>
      <link>https://kuhungio.me/2021/interpretable-machine-learning/</link>
      <pubDate>Fri, 22 Jan 2021 15:24:12 +0800</pubDate>
      
      <guid>https://kuhungio.me/2021/interpretable-machine-learning/</guid>
      <description>背景 QQ 的“安全”策略 2021年1月18日，QQ 系被爆出扫描用户的浏览器历史记录，并对特定关键词进行了记录。
QQ 的公关回应说，这是安全策略。但其实，懂的都懂，这里不做过分推演。
某种意义上讲，目前各大互联网企业的竞争，实质上是数据的竞争。
数据越多越好 作为调参从业人员，从算法和模型角度来说，数据确实是越多越好。
数据越多，模型能捕获到的有用特征则更多。从特征状态空间，映射到实际标签的过程，会更顺畅、更准确。
我的数据谁做主 为什么大家会这么关注这个问题？有两方面的原因：
一：采集行为未经用户授权，且数据采集毫不相关。
二：日常生活中，有太多”精准“的推送。
早上刚和同事说想买 PS5，晚上各大 app 就开始展示 PS5 的商品广告。
用户可不管你用的什么方法，你拿了我的无关数据，展示了我心里想的东西。
啪的一下，两件事情就得到了关联。
现象背后的解释 心理的谬误 从心理学来讲，确实存在“孕妇效应”和“幸存者偏差”，会让我们错误地把两件事归因在一起。
即，怀孕的人，会突然发现，大街上怀孕的人变多了。但实际变多了吗？其实并没有，只是之前的注意力没在这里而已。
”幸存者“，则是那些发声的人。广告虽然会尽量投放给潜在顾客，但刚好命中前一秒有需求的，是少数。发声出来，让大家以为这是普遍现象。
算法也有“恐怖谷” 更多的则是，从用户体验层面，无理由的精准，着实会招致抵触。
在数据应用的早期，大家觉得这是个新鲜好玩的东西。但当推荐越来越离谱，仿佛读心术一般的，数据的“恐怖谷”效应也就出现了。
这和仿生人领域一样。当机器人越来越像人，人类感受到的不是亲切，而是害怕。推送太准确了，以至于让人发怵，从生理上抵触。
我模型牛逼，要什么解释性 而在研发层面，在做模型时，往往容易陷入参数狂热。
随着各种模型方法的支持，我们很容易将各类脑洞、各类特征、各类技巧糅合在一起，做出一个看起来还不错的结果。
但其实，我们很难解释，是哪部分带来的效果。是深度学习的网络结构，还是交叉几轮找不着北的特征，抑或是那不起眼的坐标信息？
大多数情况，我们给不了解释。
同行与监管的挑战 为了解决数据滥用、模型黑盒问题，业界正在发生变化：
软件提供者层面 iOS在14的版本更新中，有一个最显著的变化，引起了我的注意：系统在做应用推荐时，会给出推荐的理由。
而这，在此前的版本都是没有的。
例如连上蓝牙耳机时，屏幕的下方会显示：推荐xx音乐，因为连上蓝牙时经常这么做。
监管层面 蚂蚁上市告吹，马已经服。金融时报这样评价：
同时，大数据、人工智能等技术易导致“算法歧视”，严重损害特殊群体利益。相较于传统歧视行为，算法歧视更难约束。
其一，算法歧视维度多元。传统歧视行为通常依据性别、学历等显著外在特征，但算法能挖掘更深层次的隐形特征作为依据。
其二，算法歧视形式隐蔽。基于种族、性别、民族等特征的歧视行为被法律禁止，但自动化决策可利用“算法的不可解释性”规避职责，在不触犯现有法律规定的情况下，侵犯消费者合法权益。
尤其是当某一个大型互联网企业拥有涉及数亿消费者天量数据信息的情况下，即使从个体和逐笔看，其数据来源和使用均获得了消费者授权，但从总体看，可能存在“合成的谬误”，这些数据在总体上具有公共品性质，其管理、运用并非单一消费者授权就能解决其合法性问题。
这说明，监管已经注意到这个层面。且他们的认知很专业，抓住了问题的核心：无法解释的算法，隐藏在超参数背后的歧视，将会侵犯我们每个人的权益。
这次他们没有“喝茶看报打哈哈”。
数据来源需合法合规，模型解释也应该有所依据。
模型的可解释性，必须提上议程。
下面内容比较生涩，我尽量做到深入浅出，小白看了懂大概，同行看了知方法。
我们需要可解释性 可解释的3大必要性 对于用户：用户需要知道，你有没有“偷窥”他的隐私，是否有私底下采集用户数据，用于歧视性定价等。
这会影响用户忠诚度和品牌美誉度。
如果总是很“精准”地推一些东西，用神经网络或者是组合特征、泛人群特征，用户实际是会很懵逼的。
信息不对称的情况下，他会直接联想到最近的行为，从而产生被监视的感觉。
对于监管，监管部门有责任掌握细节，防止信息的滥用与风险的滋生。
就像针对蚂蚁金服的调查：用户的多维度数据被企业用来谋求更大利益，滋生出巨大的金融系统性风险。
对于业务，业务方需要知道每个模型背后的原理，以便更好的做出决策。
一些并不面向前端用户的项目，业务方需要知道手底下发生的事情，以便做到能够响应变化。
模型说：a 变大，则 b 会变小。那么，当 b 变大时，业务就可以通过调大 a，进而控制 b 变小。</description>
    </item>
    
    <item>
      <title>云游戏，会是反作弊的银弹吗？</title>
      <link>https://kuhungio.me/2020/game_anti-cheat/</link>
      <pubDate>Thu, 18 Jun 2020 23:18:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2020/game_anti-cheat/</guid>
      <description>游戏反作弊，一直是各大游戏厂商头疼的问题。究其根本，游戏，本身是一种软件产品。交付到用户侧时，你永远无法穷举，玩家会怎么使用它。只要有利可图，就会有人去钻空子。
为了反作弊，各大厂商，也是用尽各种手段。除了内部的反作弊团队，还有法务团队的律师函警告，甚至直接招安外挂开发者。说到底，游戏反作弊，有没有一个终极方案呢？
数据挖掘，说是近5年的火热技术，没得跑的，甚至连电视剧里，都开始出现这个职业的主配角。
这个职业，被寄希望于做炫酷的事：**在庞杂的用户数据中，找到其特有的规律，找到导致现状的原因、预测未来的发展。**数据挖掘，在游戏反作弊，可以做些什么吗？
数据挖掘 整体行业概况 数据挖掘行业，如今有如下两个趋势：一个是计算广告，及其相关的推荐系统。这套东西，是信息流产品的核心。扩展开来，包括用户画像、用户生命周期等内容。
另一个，集中在敏感内容、反欺诈的识别上。这个方向，只要用户生产内容，就不可避免。换而言之，是 UGC 内容平台、活动平台的刚需。同时他又是一个劳动密集型工作，很适合用机器节省人力。
游戏中的数据挖掘 在游戏领域，数据挖掘又分为两个大方向。各个公司的AI lab，会去研究一些前沿技术。诸如强化学习、或者是迁移学习的事。满足玩家个性化的需求。其特点是：前瞻性强，复用性高，但落地困难。
而在业务侧，围绕玩家生命周期展开：渠道转化预估，异常渠道的识别、高潜玩家发现、流失的预测等。其特点：复杂多样、垂直性强，常需要单独建模。
游戏内，对于一个用户的刻画，十分具体。从基本的在线、消费；到玩法偏好、好友关系，都会有专门的标签画像。这些画像，帮助企业更好理解玩家，提供更细致的服务，达到 win-win 的目的。
对于多产品的公司（如：网易），数据互通，是其最迫切的需求。各产品数据独立，制约了它的社交属性，虽然在“洗用户”上表现克制，但数据资源白白浪费。如果是一家正在扩张业务线的公司，需提早防范：数据壁垒的出现。
如果把游戏反作弊抽象，实际也是风险控制的一个环节。风险控制有哪些注意事项？它的核心是什么，又该如何去应对挑战呢？理解风控的这些知识，有助于我们做好反作弊。
近现代风控，起源于二战后。而后迅速发展，形成以：金融业风控为代表的垂直学科。而随着80年代互联网的发展壮大，各类风险，也随之而至。
如今，互联网上的羊毛党，垃圾信息、黑产随处可见。和正常内容，争夺着用户的注意力。同时也影响着业务安全。在业务侧，安全业务可分为两类：一类是静态的账号、内容安全；另一类则是动态的行为安全，诸如活动安全等。
风控领域浅析 风控的核心 谈起金融的核心，大家的第一个念头，一定是风控。而风控的核心，则是成本控制。而成本，则不是简单的金钱成本。除了财力、物力、人力，这样的企业端成本，还应该注意，用户侧的成本。比如：用户体验的成本。
如今，互联网上，打开app前10s流失的用户，其数量之大，很可能超乎你的想象。如果为了风险控制，而过分牺牲用户体验，其实是得不偿失的。如12306的验证码，它的本意是防范刷票风险，若图库的区分度小到极端，则是过分牺牲了用户体验。
除了资源成本和用户体验成本，还有一个容易忽视的，是企业的信用成本。虽然互联网的记忆，只有短短7天；玩弄话术，运用公关手段，能够消除一时的风险。但对企业长期的公信力，其实是一种消磨。
产品出问题了，还可以修补。信用丢了，那就找不回了。
风控的挑战与应对 风控，显著性地，不同于其他业务。其他业务，存在的业务逻辑失效，是来自场景、数据、时间的漂移。即，随着时间、事态的发展，运用场景、数据表现产生了分布上的改变。而风控，则来自于强烈的对抗。道高一尺，魔高一丈。
传统意义上，为了应对风险，衍生出4种模式：
回避风险 控制风险 转移风险 承受风险 一般来说，企业主要精力，花在控制风险上。不是所有风险，都可以回避。在控制风险的同时，也可转移部分风险，最后准备承受风险。这部分，在之前的文章《浅谈互联网风控——从策略到技术》有详细介绍。
策略上，分为前中后。前：打标签，标记风险用户、风险内容。中：拦截风险，对高危操作进行干预。后：回顾每个环节，堵住漏洞。同时辅以核心指标的监控，在所有措施失效时，留一手兜底措施。
技术上，给用户准备丰富的画像，从自然人、设备、账号等角度，刻画用户。用以支持风险的识别，策略的实施。
最后，别忘了它的对抗特性。这要求我们，持续不断的演进技术、策略和手段。
游戏作弊，其实就是游戏内的风险。它不仅会影响游戏产品的体验，使产品走向，偏离策划的初衷。更会影响玩家间的平衡，进而影响产品的营收。更进一步的，让游戏失去吸引力，导致产品失败。
游戏反作弊 作弊的形式及手法 谈到作弊的形式，不妨从一个玩家的角度出发。为了获得碾压感，满足感，玩家会从以下方面入手：
为了获得满足感，玩家会修改道具获取逻辑，不付费、或者修改货币值，获得道具和服饰。
为了获得数值上的优势，调高伤害、减轻承伤。诸如“无敌”或者“锁血”，可属于这一类。
而对于时间换物资的“肝”玩法，则通过修改产出逻辑、或改变游戏内的时间节奏获取。
而在信息不对称玩法中，则通过读取数据，以此获得优势。例如：吃鸡游戏中的透视。
上述的种种作弊，其核心在于数值，其次在于程序逻辑。因此，在客户端，玩家可通过注入代码、读取内存实现。在客户端与服务端通信过程中，还可伪造中间人，截取、修改数据。更甚至，反编译游戏包体，生成一个看似一样的安装包。修改内在逻辑，重新打包。
游戏反作弊的业务逻辑 反作弊业务逻辑中，最重要的一环，是误判的处理。在作弊识别上，我们可以达到99.99%的准确率。但那万分之一，也是一个鲜活的玩家。如果误判了玩家，怎么办？除了提高准确率外，还应健全机制，预留申诉、回旋的空间。不至于，因为莫须有的判罚，让忠实玩家流失。
在技术层面，游戏开发时，会有两个地方进行校验——客户端与服务端。客户端，通过基本的签名校验，保证不被篡改。服务端，则对发回的数据，再次校验，综合其它数据，进行判断。数据挖掘起的作用，则是发现、总结作弊模式。在进行业务处罚的同时，反馈到开发过程中。
效果检查方面，游戏反作弊，又有其特殊性——不可证伪。不同于广告的点击，有明确的反馈。如果一个玩家，模型说他作弊，但他声称自己没作弊。那到底，是谁有问题？
在其它业务，会用客户投诉率，作为服务质量的考核。但客诉率在这里，不是一个好指标。因为，对作弊的处罚，势必引起玩家的不瞒，投诉中真假参合。
真正应当关心的，是核心指标的变化。比如，作弊让游戏内某项资源，产出大幅加倍，我们的效果指标，则应该是该资源的产出率。
而对于实锤作弊玩家，作弊的处罚，也不仅仅局限于封禁。在强社交游戏中，封禁他的社交行为，也是一种惩罚——即能警示其它玩家，又不至于影响正常游戏行为。除此之外，对于对抗类游戏，play with cheater，也是可行的思路。
最终目的与终极方案 游戏反作弊，更像是电子世界里的警察——打击罪犯，惩恶扬善。反作弊系统，能发现并打击作弊，但想彻底根除，只有一条路：关闭服务器。所以，反作弊的终极目的，不应当是：根除所有作弊；而是，赢得玩家信任。用各种手段，减弱不平衡，保障正常玩家权益，建立玩家对系统的信心。
前段时间，云游戏出现在大家视线。除了不受终端限制的便利外，媒体更是惊呼：“这是作弊者的末日！”。因为，客户端和服务端都不在玩家侧。但仔细想想，云游戏，真的是反作弊的终极方案吗？替考是作弊，AI 替打游戏呢？物理外挂，算不算作弊呢？
所以说，反作弊就是个开放世界游戏，当你以为快通关时，又会有新的冒险，等着你出发。
关于作者</description>
    </item>
    
    <item>
      <title>如何计算用户生命周期价值（CLV）</title>
      <link>https://kuhungio.me/2019/lifetimes/</link>
      <pubDate>Wed, 25 Dec 2019 23:28:09 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/lifetimes/</guid>
      <description>在用户关系管理中，常会遇到些直击灵魂的问题：
这批用户到底价值几何？
为什么要用这种措施去干预用户，而不是另一种方式。
为什么干预这类用户，而不去干预另一类，他们的划分标准是什么。
有这些问题，实质是因为对客户价值不够了解，缺乏行之有效的划分方式。
用户精细化运营价值巨大 随着人口红利的消失，增长逐渐见顶，急需在现有用户池做学问。过去粗放式的买量策略已经不再生效，一是买量成本逐渐高企，二是买量带来的用户忠诚度极低。对现有客户群体的划分和互相倒流，成为重中之重。行业中的黑话“洗用户”，即是讲的这一策略。
对于如何划分用户，不用的职能会有不同的看法。产品有产品的看法，可能基于某项功能偏好；运营有运营的看法，是各种活动玩法的定义；甚至领导还有他的一套看法。但是，无论怎么切入，商业的核心拿捏住，才会八九不离十。
什么是商业的本质：商业的本质是获利。因此，我们从用户的货币价值切入，评估和划分用户的生命周期。
用户生命周期价值，这并不是学界的新鲜产物，该理论在上世纪80年代就已经提出。但对于互联网，网上可搜寻到的资料少之又少。可能的原因有两个：一是互联网在过去20年快速爆发，风口上躺着也能赚钱；二是各家的策略内部不统一，无法形成统一的口径。
但这些都不是不去应用他的理由，反而说明其中价值巨大。这里，我们剥离开复杂的商业逻辑，仅从交易入手，分析用户的生命周期价值，以及用户所处的状态。
用户生命周期价值（CLV） 随着精细化运营的铺开，过去粗放式的、买量用户已经不再买账。每个用户所能接受的最低服务各不相同。如何根据用户价值，进行资源的有效利用。最大化杠杆的使用，成为企业生死的关键。
过去，没有统一的理论出现在互联网应用或是游戏中。但是，运用跨学科的思维，就可以发现：市场营销领域已进行过研究，并给出了精度极高、可解释性强的模型方法。
这种方法，就叫做用户生命周期价值，英文名称 Customer Life Time Value，简称 CLV 或者 LTV。
CLV 是什么 用户生命周期，是一种刻画用户的方法。一般用来解决两类问题：
用户还有多少价值、用以衡量投入产出比 在干预用户后，根据用户生命周期价值的变化，优化资源的投放。 即用户管理的两个核心问题：用户所具备的价值以及策略的有效性。
需要注意的是，CLV 的产品形态要求非合约。合约在国内最有代表的是合约手机。一般互联网产品，合约形态较为少见。
CLV 的用户群体需已经产生交易，未付费用户不纳入考量。当然，概念迁移，将付费换成活跃或内容消费，该模型也能处理。
CLV 回答哪些问题 用户活跃还是流失，用户还有多少付费潜力，用户在未来某段时间会否再次购买。这三个问题，是用户生命周期价值能够回答的。
如何在自家产品中引入 CLV 应用场景 判断用户所处生命周期阶段 预测用户指定周期内购买概率 预测用户的生命周期价值 通过历史付费数据，预测未来付费 活跃与流失的定义 定义：
用户有交互为活跃
用户一段时间不交互，即为流失
lifetims 工具包引入 安装 python 的工具包：
pip install lifetimes CLV 数据挖掘 用户生命周期判定，需要三个指标
frequency 用户登录的频率，这里为周期内的天数 recency 用户的最大周期，即第一次活跃到最后一次活跃 T 用户所处阶段，第一次活跃到观察周期结束 对于付费预测，还需要用户的平均付费金额。
数据获取 从数据库获取 SELECT customer_id, COUNT(distinct date(transaction_at)) - 1 as frequency, datediff(&amp;#39;day&amp;#39;, MIN(transaction_at), MAX(transaction_at)) as recency, AVG(total_price) as monetary_value, datediff(&amp;#39;day&amp;#39;, CURRENT_DATE, MIN(transaction_at)) as T FROM orders GROUP BY customer_id python 处理 from lifetimes.</description>
    </item>
    
    <item>
      <title>深度强化学习技巧 hacks for training deep RL</title>
      <link>https://kuhungio.me/2019/training_rl_systems_hacks/</link>
      <pubDate>Thu, 02 May 2019 11:59:48 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/training_rl_systems_hacks/</guid>
      <description>深度强化学习技巧 hacks for training deep RL 这是一篇旧文，John Schulman 《深度增强学习研究基础》演讲(Aug 2017)中记录的 tricks。近日重看，发现有些东西在工程中是通用的，值得一读。 测试新算法的技巧 简化问题，使用低维变量。 使用类似只有角度和速度两个变量的 Pendulum problem 问题。 这样做方便将目标函数、算法的最终状态以及算法的迭代情况可视化出来。 当出现问题时，更容易将出问题的点直观的表达（比如目标函数是否够平滑等问题）。 构造一个 demo 来测试你的算法 比如：对于一个分层强化学习算法，你应该构造一个算法可以直观学习到分层的问题。 这样能够轻易地发现那里出了问题。 注意：不要在这样的小问题上过分的尝试。 在熟悉的场景中测试 随着时间的推移，你将能预估训练所需的时间。 明白你的奖赏是如何变化的。 能够设定一个基线，以便让你知道相对过去改进了多少。 作者使用他的 hpper robot，因为他知道算法应该学多块，以及哪些行为是异常的。 快速上手新任务的技巧 简化问题 从简单的开始，直到回到问题。 途径1： 简化特征空间 举例来说，如果你是想从图片（高维空间）中学习，那么你可能先需要处理特征。举个例子：如果你的算法是想标定某个事物的位置，一开始，使用单一的x，y坐标可能会更好。 一旦起步，逐步还原问题直到解决问题。 途径2：简化奖赏函数 简化奖赏函数，这样可以有一个更快的反馈，帮助你知道是不是走偏了。 比如：击中时给 robot 记一分。这种情况很难学习，因为在开始于奖赏之前有太多的可能。将击中得分改为距离，这样将提升学习速率、更快迭代。 将一个问题转化为强化学习的技巧 可能现实是并不清楚特征是什么，也不清楚奖赏该是什么。或者，问题是什么都还不清楚。
第一步：将这个问题使用随机策略可视化出来。 看看那些部分吸引了你。
如果这个随机策略在某些情况下做了正确的事，那么很大概率，强化学习也可以做到。
策略的更新将会发现这里面的行为，并促使稳定下来。 如果随机策略永远都做不到，那么强化学习也不可能。 确保可观测 确保你能够掌控系统，且给 agent 的也是同样的系统环境。 举个例子： 亲自查看处理过图片，以确保你没有移出掉关键信息或者是在某种程度上阻碍算法。 确保所有的事物都在合理的尺度 经验法则： 观测环境： 确保均值为0，方差为1。 奖赏： 如果你能控制它，就把他缩放到一个合理的维度。 在所有的数据上都做同样的处理。 检查所有的观测环境以及奖赏，以确保没有特别离奇的异常值。 建立一个好的基线 一开始并不清楚哪些算法会起作用，所以设定一系列的基线（从其他方法）。 交叉熵 策略更新 一些类型的 Q-learning 算法: OpenAI Baselines 或者 RLLab 复现论文 某些时候（经常的事），复现论文结果特别困难。有如下一些技巧：</description>
    </item>
    
    <item>
      <title>机器学习建模与部署--以垃圾消息识别为例</title>
      <link>https://kuhungio.me/2019/flask_vue_ml/</link>
      <pubDate>Sat, 20 Apr 2019 14:31:26 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/flask_vue_ml/</guid>
      <description>前言 学历与定位 近日在某论坛，有网友提问道：搞机器学习是不是要博士或是硕士学历，是不是要求很高，顶会论文？本科生或者更低学历的，是不是就没有机会了？从最近公司的招聘来看，算法工程师的 bar 确实有在提高。但在某些事业部，仍需要很大的人力来做落地场景。每个人都要找准自己的定位，公司也有它的部门定位。
如果是发论文、要在学术界站稳脚跟，给投资人“我们很重视最新技术”的信心，那博士确实很重要。另一个角度，从实用角度来说，研究生和本科生可能性价比更高。当然，作为一个本科就业的人，如果没有较为丰富的实战经验；有机会的话，还是拿到硕士及更高学历比较好。这里的实战经验就比如：搭建一个完整的、涉及算法模型、后端及前端的系统。
模型算法的实用主义 机器学习的实用主义，不是在论文多少，而是用正确的方法去解决正确的问题。而作为背后的工程师，除了调参、除了写 sql，做调包侠、做 sql boy、报表 boy 以外，在之前的文章也提到过，要学会做正确的展示，做全套的工程化实施。毕竟，等排期很难受；有些情况前后端资源不够，或者优先级很低，那就需要自己动手了。以下以上面的垃圾邮件分类为例子，说明该如何搭建一个前后端完整的机器学习系统。
这里将本次的任务拆解，分为三个部分来讲。后端 flask、前端 Vue、ML 模型采用 flair，项目地址 kuhung/flask_vue_ML
后端 flask 相关依赖的安装 pip install -r requirements.txt
核心函数 导入函数包 from flask import Flask, jsonify, request from flask_cors import CORS # 做跨域的准备 from flask import session # 追踪客户端会话 from flair.models import TextClassifier # 模型导入，采用前不久开源的 flair 做文本分类 from flair.data import Sentence 准备工作 app = Flask(__name__) # 声明准备 app.secret_key = &amp;#34;super_secret_key&amp;#34; CORS(app) classifier = TextClassifier.</description>
    </item>
    
    <item>
      <title>机器学习项目的完整生命周期 Hands On Machine Learning in Industry </title>
      <link>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</link>
      <pubDate>Mon, 01 Apr 2019 19:28:32 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/hands-on_machine_learning_in_industry/</guid>
      <description>机器学习这东西，在学术界产出颇多，但在工业界，却很少落地。究其原因，是理念落地不够彻底，很多从业者和相关上下游不理解所致。这次就这这个机会，梳理下一个机器学习，从立项到落地再到结束，他的完整生命周期该是什么样子的。这里参考了《Hands-On Machine Learning with Scikit-Learn and Tensorflow》，值得一提的是这本书写的很不错，和《集体智慧编程》有一拼，建议阅读英文原著或东南大学出的影印版。
机器学习项目的生命周期 问题定义 定义问题，并关注大局 数据处理
获取数据 探索性的数据分析 清洗数据，为接下来的模型做准备 模型方案
探索不同的模型并挑选合适的模型 对模型进行微调，并集成为更好的模型 解决方案呈现 部署维护
部署、监控并维护系统 定义问题，从大局出发 和业务团队一起定义问题目标 我们的解决方案将会如何发挥作用 现在的解决方案是什么样的（如果有） 你将如何定义这个问题（有监督、无监督，在线还是离线） 结果该如何衡量 衡量方法是否和商业目标一致 要达成这一目标，至少的表现该是什么样子的 类似的问题是什么？有无可复用的经验与工具 我们有专家知识吗 你将如何着手解决这个问题 列出你或者别人目前所作的努力 如果可能，对假说进行验证 获取数据 建议：尽量自动化以更容易地方式获取最新的数据
列出你所需的数据以及体量 找寻并记录下获取数据的方式 检查数据将占据多少空间 检查是否有法律风险，如有必要请获得许可 获取许可 创建工作空间，确保存储足够大 获取数据 转换数据的格式以便能够方便操作（不需要改变数据本身） 确保敏感信息被删除或保护加密（匿名） 检查数据的大小和类型（时间序列、采样、地理信息等） 划分测试集，把他放一边，并且不再去动他（防止数据泄露） 探索数据 建议：在该阶段尽量获取领域专家的意见
创建数据的副本以便做数据探索（如果数据量太大，做降采样处理） 创建 Jupyter notebook 以便保存探索记录 研究每个属性及其特征 名称 类型（类别，整型/浮点，有无上下界，文本，结构化等） 缺失值 噪声数据（随机数，异常值，四舍五入的误差） 对本任务可能有用的数据 分布类型（高斯分布，均匀分布，指数分布） 对于有监督问题：确定目标对象 可视化数据 研究变量间的相关性 研究你将如何着手解决此问题 确认比较有希望的解决方案 确认有用的外部数据 将以上信息存档记录下来 准备数据 建议：
在数据的副本上操作（保持原始数据不被影响） 将你所作的数据变换写成函数，有以下5个原因 便于在本项目的新数据上复用 便于在别的项目中复用 快速清洗和准备测试集 在立项后，能够及时对数据进行处理 让数据变换过程也能作为超参数的一份子，进行调参 数据清洗 调整或移除异常值（可选） 填补缺失值（0，平均数、中位数），或者简单的去掉缺失的样本或特征 特征选择（可选） 去掉对本任务无用的信息 特征工程，适度 连续数值离散化 特征分解（分类特征、时间特征等） 特征变换（log(x),sqrt(x),x^2等） 特征组合 特征尺度变换：标准化或归一化 挑选合适的模型 建议：</description>
    </item>
    
    <item>
      <title>用先知模型预测股市 Prophet in 000300 </title>
      <link>https://kuhungio.me/2019/prophet-in-000300/</link>
      <pubDate>Fri, 08 Mar 2019 22:48:45 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/prophet-in-000300/</guid>
      <description>跑步进场 最近股市大涨，不少人忙着跑步进场。作为保守型“投资者”，主投指数基金：沪深300。在这波行情 中，短短2个月，也有13%的账面收益。虽然知道指数类适合长期持有，但也好奇，这个点是否是高位了。为了解决这个疑虑。我们今天用算法模型套一套，看能否发现些什么。
时序预测的价值 时序问题的预测在生活中很常见。例如：游戏在线人数预测、消费情况预测、 O2O 的到店人数预测、交通流量预测，这些场景的精确预测，为资源的调配起到了重大的参考作用。从个体角度来说，得到的服务和体验也大大提升。
为此，Facebook 开源了一套工具 Prophet，专门用于时间学列预测。在这里，我们将用它，来一探股市究竟。
时序预测的原理 对于时间序列问题，常用的手法是时间序列的分解：这里有些类似于傅里叶变换的意味。将一个函数分解为多个规律函数的和积。时间序列的常见组成成分包括：季节项、趋势项以及噪声。在 Prophet 中，结合实际情况，他们又加入了节假日项目。之前在一次 kaggle 的比赛中，我们也发现节假日的数据波动，其实是类似于周末效应的。即：节假日的前后数据，类似于周六的前后数据。对数据进行修正后，评价指标会好很多。
废话不多说，咱们开干。
Prophet in 沪深300 工具包安装 pip install fbprophet
数据准备与清洗 import pandas as pd import numpy as np from fbprophet import Prophet 数据准备
数据来源为网易财经，沪深三百指数。 data = pd.read_csv(&amp;#39;../data/000300.csv&amp;#39;,encoding=&amp;#39;GB2312&amp;#39;) data.head() 数据清洗
选取需要的数据，并对数据做 log / box-cox 变换，使数据更符合线性、正态分布，减少方差差异。经济系统和生态系统类似，都存在指数级增长现象，也存在饱和现象。我们这里采用 log 变换。 df = data[[u&amp;#39;日期&amp;#39;,u&amp;#39;收盘价&amp;#39;]] df.columns = [&amp;#39;ds&amp;#39;,&amp;#39;y&amp;#39;] df[&amp;#39;y&amp;#39;] = df[&amp;#39;y&amp;#39;].apply(lambda x: np.log(int(x))) 模型拟合与预测 简单定义，然后拟合。
m = Prophet() m.fit(df) 预测未来一年的行情
future = m.</description>
    </item>
    
    <item>
      <title>What is Data Mining 什么是数据挖掘</title>
      <link>https://kuhungio.me/2019/what-is-data-mining/</link>
      <pubDate>Sun, 17 Feb 2019 00:40:20 +0800</pubDate>
      
      <guid>https://kuhungio.me/2019/what-is-data-mining/</guid>
      <description> 一、数据挖掘的定义 什么是数据挖掘？ 数据挖掘是一个用数据发现问题、解决问题的学科。 通常通过对数据的探索、处理、分析或建模实现。 数据挖掘学习路线 大学里并没有数据挖掘这么一个专业，现有的数据挖掘工程师大都来自工科或统计学等专业。 目前的数据挖掘工程师大都来自不同背景，计算机科学、数学甚至是机械工程。要想成功胜任，其诀窍是热情、好奇心，不断学习新的工具的能力，以及对数据清洗和分析的耐心。 给新人的建议 最重要的三个品质：好奇心、是非观以及批判性思考。这三个品质，放在其他领域同样适用。 专业领域的三种能力：编程能力、统计基础、商业思维。编程和统计在大学较为容易学到，商业思维需要多实践总结。 二、数据挖掘在做什么 数据挖掘工程师的一天 检查日常报表数据是否异常，寻求数据波动的合理解释。 针对新业务，设计指标，搭建数据模型。 搭建商品推荐系统、价格预测系统、文本分类系统或是聊天机器人。 数据挖掘的算法 使用复杂的机器学习算法并不能保证效果。一般来讲，最好的解决办法，通常很简单。 生产环境使用简单的算法，并不意味着要放弃前沿算法。每一套新的方法，其目的都在解决前面的薄弱之处。 数据挖掘与服务器 本地 PC 由于硬件与系统限制，工程师常在服务器进行大规模数据的运算、脚本部署与接口部署。 三、商业中的数据挖掘 作为公司，该如何开展数据挖掘 评估可能的收益与需要的投入 开始收集数据 招募数据挖掘团队 招聘数据挖掘团队 好奇心应该是数据挖掘从业者的最重要品质。 招聘时，应确保候选人对工作内容感兴趣。 候选人应具备一定的成果意识。商业更重成果，而不是过程。 数据挖掘应用 广告位点击预估 信用卡风控评估 用户流失干预 四、数据挖掘工具 数据挖掘工具与大数据 掌握以下工具：Python、Linux、Pandas 及 Jupyter、关系型和非关系型数据库。 大数据通常指传统数据系统无法处理的数据。体量和增速都相当大。处理工具以 Hadoop 为代表。 五、数据挖掘进阶 神经网络和深度学习 神经网络出现已数十年，但由于条件限制，这一方向搁置了数十年。目前随着新的优化方法的出现和算力的提升，这一方向的工业化逐渐成为可能。 如何更上一层楼 掌握基本的编程知识，更多地去理解背后的原理。 流程化意识，及时复盘总结，规范流程（复用）。 成果导向，将知识转化为行动和成果，给他人带来价值，服务更多人。 </description>
    </item>
    
    <item>
      <title>一场 kaggle 比赛总结出的时间序列处理技巧 time series problem summary </title>
      <link>https://kuhungio.me/2018/time-series-problem-summary/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kuhungio.me/2018/time-series-problem-summary/</guid>
      <description>Source https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion
总结一：保证数据同分布 验证集的选取，分布上应尽量靠近测试集。
方式一:：对抗验证集的生成。 方式二： 就近选取相同天数。 方式三:：类比属性。如本赛题 &amp;ldquo;golden week&amp;rdquo; 与 &amp;ldquo;new year&amp;rdquo; 类比，选取 &amp;ldquo;new year&amp;rdquo; 段作为验证集。 tips: kfold 用在时间序列上不合适，会有数据泄露风险。正确的方法应是滑窗。
总结二：异常值特殊处理 一些特殊的时间节点（或者说是异常值），应该予以特殊考虑。比如本次比赛中的 &amp;ldquo;golden week&amp;rdquo;.。需要对其进行变换，而不是直接依靠模型的预测结果。
方式一:：等同法 The rules:
Treat holiday as Saturday
If the day before holiday is weekday ,treat the day before holiday as Friday If the day after holiday is weekday ,treat the day after holiday as Monday it work not only golden week but also a lot other holidays.</description>
    </item>
    
  </channel>
</rss>
